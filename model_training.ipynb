{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "class MappingNetwork(keras.Model):\n",
    "    def __init__(self, latent_dim, style_dim, num_layers):\n",
    "        super(MappingNetwork, self).__init__()\n",
    "        self.network = keras.Sequential([\n",
    "            keras.layers.Dense(style_dim, activation='relu')\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "    \n",
    "    def call(self, z):\n",
    "        return self.network(z)\n",
    "\n",
    "class AdaIN(keras.layers.Layer):\n",
    "    def __init__(self):\n",
    "        super(AdaIN, self).__init__()\n",
    "    \n",
    "    def call(self, x, style):\n",
    "        mean = tf.reduce_mean(x, axis=[1, 2], keepdims=True)\n",
    "        std = tf.math.reduce_std(x, axis=[1, 2], keepdims=True) + 1e-8\n",
    "        y = (x - mean) / std\n",
    "        \n",
    "        style = tf.reshape(style, [-1, 1, 1, style.shape[-1]])\n",
    "        return y * style[:, :, :, :x.shape[-1]] + style[:, :, :, x.shape[-1]:]\n",
    "\n",
    "class StyleLayer(keras.layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, upsample=False):\n",
    "        super(StyleLayer, self).__init__()\n",
    "        self.upsample = upsample\n",
    "        self.conv = keras.layers.Conv2D(filters, kernel_size, padding='same')\n",
    "        self.adain = AdaIN()\n",
    "        self.activation = keras.layers.LeakyReLU(0.2)\n",
    "    \n",
    "    def call(self, x, style):\n",
    "        if self.upsample:\n",
    "            x = tf.image.resize(x, (x.shape[1]*2, x.shape[2]*2), method='bilinear')\n",
    "        x = self.conv(x)\n",
    "        x = self.adain(x, style)\n",
    "        return self.activation(x)\n",
    "\n",
    "class Generator(keras.Model):\n",
    "    def __init__(self, latent_dim, style_dim, num_layers, channels):\n",
    "        super(Generator, self).__init__()\n",
    "        self.mapping = MappingNetwork(latent_dim, style_dim, num_layers)\n",
    "        self.initial_const = tf.Variable(tf.random.normal([1, 4, 4, channels[0]]))\n",
    "        self.style_layers = [\n",
    "            StyleLayer(ch, 3, upsample=True) for ch in channels[1:]\n",
    "        ]\n",
    "        self.to_rgb = keras.layers.Conv2D(3, 1, activation='tanh')\n",
    "    \n",
    "    def call(self, z):\n",
    "        w = self.mapping(z)\n",
    "        x = tf.tile(self.initial_const, [tf.shape(z)[0], 1, 1, 1])\n",
    "        \n",
    "        for layer in self.style_layers:\n",
    "            x = layer(x, w)\n",
    "        \n",
    "        return self.to_rgb(x)\n",
    "\n",
    "class Discriminator(keras.Model):\n",
    "    def __init__(self, channels):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.layers_list = [\n",
    "            keras.layers.Conv2D(ch, 3, strides=2, padding='same', activation='leaky_relu')\n",
    "            for ch in reversed(channels)\n",
    "        ]\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, x):\n",
    "        for layer in self.layers_list:\n",
    "            x = layer(x)\n",
    "        x = self.flatten(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "class StyleGAN(keras.Model):\n",
    "    def __init__(self, latent_dim=512, style_dim=512, num_layers=8, channels=[512, 256, 128, 64]):\n",
    "        super(StyleGAN, self).__init__()\n",
    "        self.generator = Generator(latent_dim, style_dim, num_layers, channels)\n",
    "        self.discriminator = Discriminator(channels)\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, g_optimizer, d_optimizer, loss_fn):\n",
    "        super(StyleGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        latent_vectors = tf.random.normal([batch_size, self.latent_dim])\n",
    "        \n",
    "        with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "            fake_images = self.generator(latent_vectors)\n",
    "            \n",
    "            real_output = self.discriminator(real_images)\n",
    "            fake_output = self.discriminator(fake_images)\n",
    "            \n",
    "            g_loss = self.loss_fn(tf.ones_like(fake_output), fake_output)\n",
    "            d_loss = self.loss_fn(tf.ones_like(real_output), real_output) + \\\n",
    "                     self.loss_fn(tf.zeros_like(fake_output), fake_output)\n",
    "        \n",
    "        g_gradients = g_tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        d_gradients = d_tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "        \n",
    "        self.g_optimizer.apply_gradients(zip(g_gradients, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(d_gradients, self.discriminator.trainable_variables))\n",
    "        \n",
    "        return {\"g_loss\": g_loss, \"d_loss\": d_loss}\n",
    "\n",
    "# Usage example\n",
    "latent_dim = 512\n",
    "style_dim = 512\n",
    "num_layers = 8\n",
    "channels = [512, 256, 128, 64]\n",
    "batch_size = 32\n",
    "\n",
    "model = StyleGAN(latent_dim, style_dim, num_layers, channels)\n",
    "model.compile(\n",
    "    g_optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.0, beta_2=0.99, epsilon=1e-8),\n",
    "    d_optimizer=keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.0, beta_2=0.99, epsilon=1e-8),\n",
    "    loss_fn=keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "# Generate dummy data for demonstration\n",
    "dummy_images = tf.random.normal([batch_size, 64, 64, 3])\n",
=======
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benbradshaw/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.preprocessing.preprocessing import preprocess\n",
    "from src.evaluation.losses import generator_loss, discriminator_loss, combined_metric\n",
    "from src.misc.plotting import plot_loss\n",
    "from src.misc.saving import generate_and_save_images, save_loss\n",
    "\n",
    "from src.models.wgan_gp import create_generator, create_discriminator, WGAN_GP\n",
    "from src.models.style_gan import StyleGAN\n",
    "from src.models.ddpm import DDPM\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.list_files('./data/10000_images_downscaled/*')\n",
    "\n",
    "ds = ds.map(preprocess(tanh=True)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x105784be0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = next(iter(ds))\n",
    "sample_image = sample[0].numpy()\n",
    "plt.title('Sample Image')\n",
    "plt.imshow(sample_image*0.5 + 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WGAN_GP Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_DIM = 100\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "generator =  create_generator(input_shape=LATENT_DIM)\n",
    "discriminator = create_discriminator(input_shape=(64, 64, 3))\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, \n",
    "\t\t\t\t\t\t\t\t\tbeta_1=0.5,\n",
    "\t\t\t\t\t\t\t\t\tbeta_2=0.9\n",
    "\t\t\t\t\t\t\t\t\t)\n",
    "\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, \n",
    "\t\t\t\t\t\t\t\t\tbeta_1=0.5,\n",
    "\t\t\t\t\t\t\t\t\tbeta_2=0.9\n",
    "\t\t\t\t\t\t\t\t\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgan_gp = WGAN_GP(generator, discriminator, latent_dim=LATENT_DIM)\n",
    "\n",
    "wgan_gp.compile(\n",
    "    disc_optimizer=discriminator_optimizer,\n",
    "    gen_optimizer=generator_optimizer,\n",
    "    disc_loss_fn=discriminator_loss,\n",
    "    gen_loss_fn=generator_loss,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully from checkpoint.\n"
     ]
    }
   ],
   "source": [
    "checkpoint_dir = './src/model_checkpoints/wgan_gp_checkpoints/'\n",
    "checkpoint_prefix = checkpoint_dir + \"wgan_gp_ckpt\"\n",
    "\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)\n",
    "\n",
    "checkpoint_manager = tf.train.CheckpointManager(checkpoint, directory=checkpoint_dir, checkpoint_name=checkpoint_prefix, max_to_keep=1)\n",
    "\n",
    "\n",
    "try:\n",
    "    checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "    batch = next(iter(ds))\n",
    "\n",
    "    noise = tf.random.normal([BATCH_SIZE, LATENT_DIM])\n",
    "\n",
    "    gen_images = generator(noise)\n",
    "\n",
    "    real_output = discriminator(batch, training=False)\n",
    "    fake_output = discriminator(gen_images, training=False)\n",
    "\n",
    "    disc_loss = discriminator_loss(real_logits=real_output, fake_logits=fake_output)\n",
    "    gen_loss = generator_loss(fake_logits=fake_output)\n",
    "\n",
    "    best_combined_loss = combined_metric(gen_loss=gen_loss, disc_loss=disc_loss, alpha=0.75)\n",
    "\n",
    "    print(\"Model loaded successfully from checkpoint.\")\n",
    "except:\n",
    "    best_combined_loss = np.inf\n",
    "    print(f\"Error: Checkpoint file '{checkpoint_prefix}' not found. Model not loaded.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(wgan, images):\n",
    "    return wgan.train_step(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/313 [00:06<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(ds):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwgan_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:917\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# If we did not create any variables the trace we have is good enough.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m   filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    913\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_concrete_variable_creation_fn\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m    914\u001b[0m           bound_args\n\u001b[1;32m    915\u001b[0m       )\n\u001b[1;32m    916\u001b[0m   )\n\u001b[0;32m--> 917\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    918\u001b[0m \u001b[43m      \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concrete_variable_creation_fn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn_with_cond\u001b[39m(inner_args, inner_kwds):\n\u001b[1;32m    923\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Conditionally runs initialization if it's needed.\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate a fixed noise vector for image generation\n",
    "tf.random.set_seed(42)\n",
    "fixed_noise = tf.random.normal([16, LATENT_DIM])\n",
    "best_combined_loss = np.inf\n",
    "loss_path = './src/model_training_losses/wgan_gp_train_loss.csv'\n",
    "image_dir = './src/training_images/wgan_gp_images/'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for batch in tqdm(ds):\n",
    "        dict = train_step(wgan_gp, batch)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    gen_loss = dict['gen_loss'].numpy()\n",
    "    disc_loss = dict['disc_loss'].numpy()\n",
    "\n",
    "    # Save loss\n",
    "    save_loss(loss_path=loss_path, gen_loss=gen_loss, disc_loss=disc_loss)\n",
    "\n",
    "    # Generate plots\n",
    "    display.clear_output(wait=True)\n",
    "    print(f'Epoch {epoch+1} took {end - start} seconds')\n",
    "    generate_and_save_images(model=wgan_gp, noise=fixed_noise, epoch=epoch + 1, image_dir=image_dir)\n",
    "    plot_loss(loss_path=loss_path)\n",
    "\n",
    "    # Check loss\n",
    "    combined_loss = combined_metric(gen_loss, disc_loss, alpha = 0.75)\n",
    "    if combined_loss < best_combined_loss:\n",
    "        best_loss = combined_loss\n",
    "        checkpoint_manager.save()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StyleGAN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training step completed\n",
      "Sample image generated\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "LATENT_DIM = 512\n",
    "STYLE_DIM = 512\n",
    "NUM_LAYERS = 8\n",
    "CHANNELS = [512, 256, 128, 64]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = StyleGAN(LATENT_DIM, STYLE_DIM, NUM_LAYERS, CHANNELS)\n",
    "model.compile(\n",
    "    g_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.0, beta_2=0.99, epsilon=1e-8),\n",
    "    d_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.0, beta_2=0.99, epsilon=1e-8),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "# Generate dummy data for demonstration\n",
    "dummy_images = tf.random.normal([BATCH_SIZE, 64, 64, 3])\n",
>>>>>>> aa25840 (Laptop commit)
    "\n",
    "# Train for one step (in practice, you would train for many steps)\n",
    "model.train_step(dummy_images)\n",
    "\n",
    "print(\"Training step completed\")\n",
    "\n",
    "# Generate a sample image\n",
<<<<<<< HEAD
    "sample_latent = tf.random.normal([1, latent_dim])\n",
=======
    "sample_latent = tf.random.normal([1, LATENT_DIM])\n",
>>>>>>> aa25840 (Laptop commit)
    "generated_image = model.generator(sample_latent)\n",
    "print(\"Sample image generated\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# Define the generator network\n",
    "def make_generator():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(128, input_shape=(100,)),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.ReShape\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(512),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(784, activation='tanh')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the critic network\n",
    "def make_critic():\n",
    "    model = keras.Sequential([\n",
    "        keras.layers.Dense(512, input_shape=(784,)),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(256),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(128),\n",
    "        keras.layers.LeakyReLU(alpha=0.2),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the WGAN model\n",
    "class WGAN(keras.Model):\n",
    "    def __init__(self, critic, generator, latent_dim, critic_extra_steps=5):\n",
    "        super(WGAN, self).__init__()\n",
    "        self.critic = critic\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.c_extra_steps = critic_extra_steps\n",
    "\n",
    "    def compile(self, c_optimizer, g_optimizer, c_loss_fn, g_loss_fn):\n",
    "        super(WGAN, self).compile()\n",
    "        self.c_optimizer = c_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.c_loss_fn = c_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        for _ in range(self.c_extra_steps):\n",
    "            random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "            with tf.GradientTape() as tape:\n",
    "                fake_images = self.generator(random_latent_vectors)\n",
    "                fake_logits = self.critic(fake_images)\n",
    "                real_logits = self.critic(real_images)\n",
    "\n",
    "                c_loss = self.c_loss_fn(real_logits, fake_logits)\n",
    "                \n",
    "            c_gradient = tape.gradient(c_loss, self.critic.trainable_variables)\n",
    "            self.c_optimizer.apply_gradients(zip(c_gradient, self.critic.trainable_variables))\n",
    "\n",
    "            # Clip critic weights\n",
    "            for w in self.critic.trainable_weights:\n",
    "                w.assign(tf.clip_by_value(w, -0.01, 0.01))\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        with tf.GradientTape() as tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            generated_logits = self.critic(generated_images)\n",
    "            g_loss = self.g_loss_fn(generated_logits)\n",
    "\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gen_gradient, self.generator.trainable_variables))\n",
    "\n",
    "        return {\"c_loss\": c_loss, \"g_loss\": g_loss}\n",
    "\n",
    "# Loss functions\n",
    "def critic_loss(real_logits, fake_logits):\n",
    "    return tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "def generator_loss(fake_logits):\n",
    "    return -tf.reduce_mean(fake_logits)\n",
    "\n",
    "# Create and compile the WGAN model\n",
    "latent_dim = 100\n",
    "generator = make_generator()\n",
    "critic = make_critic()\n",
    "wgan = WGAN(critic=critic, generator=generator, latent_dim=latent_dim)\n",
    "\n",
    "c_optimizer = keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "g_optimizer = keras.optimizers.RMSprop(learning_rate=0.00005)\n",
    "\n",
    "wgan.compile(\n",
    "    c_optimizer=c_optimizer,\n",
    "    g_optimizer=g_optimizer,\n",
    "    c_loss_fn=critic_loss,\n",
    "    g_loss_fn=generator_loss\n",
    ")\n"
   ]
=======
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|         | 11/313 [00:15<07:07,  1.42s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m tqdm(ds):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwgan_gp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     17\u001b[0m gen_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1552\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1552\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1553\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1555\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1556\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1557\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1558\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1560\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1561\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1562\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1566\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1567\u001b[0m   )\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Generate a fixed noise vector for image generation\n",
    "tf.random.set_seed(42)\n",
    "fixed_noise = tf.random.normal([16, LATENT_DIM])\n",
    "best_combined_loss = np.inf\n",
    "loss_path = './src/model_training_losses/style_gan_train_loss.csv'\n",
    "image_dir = './src/training_images/style_gan_images/'\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    for batch in tqdm(ds):\n",
    "        dict = train_step(wgan_gp, batch)\n",
    "    \n",
    "    end = time.time()\n",
    "\n",
    "    gen_loss = dict['gen_loss'].numpy()\n",
    "    disc_loss = dict['disc_loss'].numpy()\n",
    "\n",
    "    # Save loss\n",
    "    save_loss(loss_path=loss_path, gen_loss=gen_loss, disc_loss=disc_loss)\n",
    "\n",
    "    # Generate plots\n",
    "    display.clear_output(wait=True)\n",
    "    print(f'Epoch {epoch+1} took {end - start} seconds')\n",
    "    generate_and_save_images(model=wgan_gp, noise=fixed_noise, epoch=epoch + 1, image_dir=image_dir)\n",
    "    plot_loss(loss_path=loss_path)\n",
    "\n",
    "    # Check loss\n",
    "    combined_loss = combined_metric(gen_loss, disc_loss, alpha = 0.75)\n",
    "    if combined_loss < best_combined_loss:\n",
    "        best_loss = combined_loss\n",
    "        checkpoint_manager.save()\n",
    "    \n",
    "    print(f'Epoch {epoch+1}/{EPOCHS}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[ 2.41487637e+01  4.84495468e+01 -1.48501320e+01]\n",
      "   [ 4.28292274e+00  2.42669601e+01 -2.58304996e+01]\n",
      "   [ 4.93575478e+00  2.39276428e+01 -2.58973980e+01]\n",
      "   ...\n",
      "   [ 4.43955421e+00  2.28249912e+01 -2.48760357e+01]\n",
      "   [ 4.30611420e+00  2.35414047e+01 -2.73256493e+01]\n",
      "   [-1.16192913e+00  7.61672211e+00 -1.57609539e+01]]\n",
      "\n",
      "  [[ 2.82384090e+01  3.76756477e+01 -1.64426155e+01]\n",
      "   [ 1.48783512e+01 -3.88193893e+00 -4.33041039e+01]\n",
      "   [ 1.45923290e+01 -2.36359406e+00 -4.32923546e+01]\n",
      "   ...\n",
      "   [ 1.44756975e+01 -3.35904694e+00 -4.24859772e+01]\n",
      "   [ 1.27098160e+01 -2.84100914e+00 -4.51885414e+01]\n",
      "   [ 2.52209377e+00  5.38952255e+00 -5.08767738e+01]]\n",
      "\n",
      "  [[ 2.88120079e+01  3.82584305e+01 -1.67539711e+01]\n",
      "   [ 1.69404869e+01 -1.78513908e+00 -4.43603172e+01]\n",
      "   [ 1.67802391e+01 -1.38906860e+00 -4.45724335e+01]\n",
      "   ...\n",
      "   [ 1.66997223e+01 -3.07822990e+00 -4.27304420e+01]\n",
      "   [ 1.45626450e+01 -3.40090942e+00 -4.43347702e+01]\n",
      "   [ 3.09134603e+00  5.37948227e+00 -5.18251839e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.09157066e+01  3.97116776e+01 -1.70713844e+01]\n",
      "   [ 1.77334900e+01 -1.52689743e+00 -4.35393524e+01]\n",
      "   [ 1.76268272e+01  1.18808746e-02 -4.24931984e+01]\n",
      "   ...\n",
      "   [ 1.78591042e+01 -1.86380005e+00 -4.12758904e+01]\n",
      "   [ 1.50592375e+01 -1.66644669e+00 -4.35350189e+01]\n",
      "   [ 3.34716225e+00  7.03438377e+00 -5.12185593e+01]]\n",
      "\n",
      "  [[ 2.81036339e+01  3.72351494e+01 -1.49685230e+01]\n",
      "   [ 1.67688999e+01 -2.59892273e+00 -4.29275322e+01]\n",
      "   [ 1.58738213e+01 -2.31807899e+00 -4.19487534e+01]\n",
      "   ...\n",
      "   [ 1.80520439e+01 -4.36818504e+00 -4.15041695e+01]\n",
      "   [ 1.56761780e+01 -4.48983955e+00 -4.30816193e+01]\n",
      "   [ 3.65392447e+00  6.85658264e+00 -5.06891327e+01]]\n",
      "\n",
      "  [[ 7.14716816e+00  1.43938284e+01 -1.24005871e+01]\n",
      "   [ 2.18283653e-01 -1.12965260e+01 -3.24477539e+01]\n",
      "   [ 1.82245255e-01 -1.13528023e+01 -3.02660751e+01]\n",
      "   ...\n",
      "   [-2.60548592e-01 -1.30584602e+01 -2.98064976e+01]\n",
      "   [-2.16879845e+00 -1.29302483e+01 -3.09013138e+01]\n",
      "   [ 7.99478197e+00 -2.70166683e+00 -4.32923355e+01]]]\n",
      "\n",
      "\n",
      " [[[ 2.59270401e+01  5.19167404e+01 -1.58841419e+01]\n",
      "   [ 4.61610413e+00  2.59005451e+01 -2.76418762e+01]\n",
      "   [ 5.20880890e+00  2.55450706e+01 -2.78178539e+01]\n",
      "   ...\n",
      "   [ 4.66579247e+00  2.45658054e+01 -2.66685104e+01]\n",
      "   [ 4.51531410e+00  2.51155014e+01 -2.89577141e+01]\n",
      "   [-1.33224869e+00  8.09403610e+00 -1.69144535e+01]]\n",
      "\n",
      "  [[ 3.04095917e+01  4.02761040e+01 -1.76652279e+01]\n",
      "   [ 1.59950104e+01 -4.13572693e+00 -4.63737602e+01]\n",
      "   [ 1.57264109e+01 -2.64597511e+00 -4.62867928e+01]\n",
      "   ...\n",
      "   [ 1.54364872e+01 -3.62720680e+00 -4.55906143e+01]\n",
      "   [ 1.36645374e+01 -3.09835434e+00 -4.82108002e+01]\n",
      "   [ 2.59705448e+00  5.84272575e+00 -5.46784821e+01]]\n",
      "\n",
      "  [[ 3.09731140e+01  4.09499397e+01 -1.81174889e+01]\n",
      "   [ 1.81135025e+01 -2.16391563e+00 -4.73735199e+01]\n",
      "   [ 1.78359489e+01 -1.52001572e+00 -4.75822258e+01]\n",
      "   ...\n",
      "   [ 1.77404957e+01 -3.31426430e+00 -4.59785271e+01]\n",
      "   [ 1.55611610e+01 -3.44924355e+00 -4.74165916e+01]\n",
      "   [ 3.21885371e+00  5.95669556e+00 -5.53084297e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.29388885e+01  4.24270096e+01 -1.82919693e+01]\n",
      "   [ 1.87850704e+01 -1.85003853e+00 -4.65541382e+01]\n",
      "   [ 1.85518875e+01 -3.44675064e-01 -4.55221062e+01]\n",
      "   ...\n",
      "   [ 1.89626694e+01 -2.13378716e+00 -4.42040253e+01]\n",
      "   [ 1.61638947e+01 -1.95722008e+00 -4.66247101e+01]\n",
      "   [ 3.54577160e+00  7.48162460e+00 -5.47175407e+01]]\n",
      "\n",
      "  [[ 3.01989346e+01  3.98939972e+01 -1.61997089e+01]\n",
      "   [ 1.79672661e+01 -2.79235268e+00 -4.59029617e+01]\n",
      "   [ 1.69629745e+01 -2.53657150e+00 -4.50236664e+01]\n",
      "   ...\n",
      "   [ 1.90962296e+01 -4.60710526e+00 -4.44691010e+01]\n",
      "   [ 1.68677216e+01 -4.75127220e+00 -4.60044403e+01]\n",
      "   [ 3.83568001e+00  7.25765419e+00 -5.42694244e+01]]\n",
      "\n",
      "  [[ 7.72624159e+00  1.53319187e+01 -1.33848877e+01]\n",
      "   [ 2.04825401e-01 -1.21960411e+01 -3.47255211e+01]\n",
      "   [ 8.31756592e-02 -1.22650414e+01 -3.24963150e+01]\n",
      "   ...\n",
      "   [-3.64051819e-01 -1.39894123e+01 -3.20955276e+01]\n",
      "   [-2.21298695e+00 -1.38728466e+01 -3.30384674e+01]\n",
      "   [ 8.52459335e+00 -2.90198421e+00 -4.64118042e+01]]]\n",
      "\n",
      "\n",
      " [[[ 1.79252338e+01  3.62504387e+01 -1.11836948e+01]\n",
      "   [ 3.29664230e+00  1.84266796e+01 -1.96098518e+01]\n",
      "   [ 3.97121239e+00  1.80891762e+01 -1.97923794e+01]\n",
      "   ...\n",
      "   [ 3.35239410e+00  1.72111378e+01 -1.85660133e+01]\n",
      "   [ 3.19362259e+00  1.77323380e+01 -2.08582497e+01]\n",
      "   [-7.46883869e-01  5.84532452e+00 -1.21895943e+01]]\n",
      "\n",
      "  [[ 2.10225277e+01  2.82747345e+01 -1.23103123e+01]\n",
      "   [ 1.11139278e+01 -3.04384804e+00 -3.26534500e+01]\n",
      "   [ 1.07962217e+01 -1.65389252e+00 -3.26158142e+01]\n",
      "   ...\n",
      "   [ 1.04332104e+01 -2.61289024e+00 -3.14957085e+01]\n",
      "   [ 8.91671848e+00 -2.26653099e+00 -3.43125191e+01]\n",
      "   [ 2.03573132e+00  3.94498253e+00 -3.80472221e+01]]\n",
      "\n",
      "  [[ 2.15790749e+01  2.86548080e+01 -1.24586620e+01]\n",
      "   [ 1.29388247e+01 -9.48604584e-01 -3.36051941e+01]\n",
      "   [ 1.29250994e+01 -4.71748352e-01 -3.38997993e+01]\n",
      "   ...\n",
      "   [ 1.27275829e+01 -2.11206055e+00 -3.22525711e+01]\n",
      "   [ 1.07073870e+01 -2.46993637e+00 -3.37594910e+01]\n",
      "   [ 2.61741805e+00  3.87164688e+00 -3.87746162e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.35555077e+01  3.03975906e+01 -1.27134914e+01]\n",
      "   [ 1.38467407e+01 -8.39462280e-01 -3.29483528e+01]\n",
      "   [ 1.36620464e+01  9.07070160e-01 -3.17721291e+01]\n",
      "   ...\n",
      "   [ 1.39931669e+01 -1.05092812e+00 -3.05882130e+01]\n",
      "   [ 1.11156788e+01 -8.06308746e-01 -3.29637299e+01]\n",
      "   [ 2.75776863e+00  5.49610710e+00 -3.81504631e+01]]\n",
      "\n",
      "  [[ 2.08455276e+01  2.78860130e+01 -1.07097893e+01]\n",
      "   [ 1.29897795e+01 -1.85674286e+00 -3.21948471e+01]\n",
      "   [ 1.19954453e+01 -1.63254738e+00 -3.12330360e+01]\n",
      "   ...\n",
      "   [ 1.40850201e+01 -3.64542007e+00 -3.06747169e+01]\n",
      "   [ 1.17538471e+01 -3.76976013e+00 -3.24390030e+01]\n",
      "   [ 3.10532999e+00  5.32241058e+00 -3.79191284e+01]]\n",
      "\n",
      "  [[ 5.19627476e+00  1.12582607e+01 -9.05099297e+00]\n",
      "   [ 4.21342850e-01 -8.04757118e+00 -2.45739326e+01]\n",
      "   [ 3.55298996e-01 -8.13901329e+00 -2.24828110e+01]\n",
      "   ...\n",
      "   [-2.60601044e-02 -9.72856140e+00 -2.21011353e+01]\n",
      "   [-1.99358034e+00 -9.70413208e+00 -2.29708576e+01]\n",
      "   [ 5.91309023e+00 -2.00449944e+00 -3.24667282e+01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 1.73479862e+01  3.50101700e+01 -1.07896318e+01]\n",
      "   [ 2.99608612e+00  1.78736305e+01 -1.88888950e+01]\n",
      "   [ 3.94287300e+00  1.73999310e+01 -1.88921356e+01]\n",
      "   ...\n",
      "   [ 3.25505066e+00  1.66516495e+01 -1.79050407e+01]\n",
      "   [ 3.11719322e+00  1.70641880e+01 -2.02009125e+01]\n",
      "   [-5.83396435e-01  5.63596725e+00 -1.17305336e+01]]\n",
      "\n",
      "  [[ 2.01574860e+01  2.72460537e+01 -1.16313133e+01]\n",
      "   [ 1.06873646e+01 -3.03987312e+00 -3.15166855e+01]\n",
      "   [ 1.04434347e+01 -1.50500870e+00 -3.13996620e+01]\n",
      "   ...\n",
      "   [ 1.00526009e+01 -2.45398140e+00 -3.07248192e+01]\n",
      "   [ 8.34052849e+00 -1.85682869e+00 -3.33229561e+01]\n",
      "   [ 1.99579048e+00  3.63553810e+00 -3.66459732e+01]]\n",
      "\n",
      "  [[ 2.08384953e+01  2.78897400e+01 -1.20372982e+01]\n",
      "   [ 1.26898746e+01 -9.13448334e-01 -3.25952530e+01]\n",
      "   [ 1.24504299e+01 -5.90404510e-01 -3.26479797e+01]\n",
      "   ...\n",
      "   [ 1.22183647e+01 -2.10353661e+00 -3.11620102e+01]\n",
      "   [ 1.02634830e+01 -2.44527435e+00 -3.27417755e+01]\n",
      "   [ 2.60832477e+00  3.79720306e+00 -3.74708710e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 2.27710400e+01  2.94185867e+01 -1.23295889e+01]\n",
      "   [ 1.33437290e+01 -6.56875610e-01 -3.16048012e+01]\n",
      "   [ 1.33941612e+01  9.52716827e-01 -3.07523804e+01]\n",
      "   ...\n",
      "   [ 1.35804482e+01 -1.11623764e+00 -2.94105835e+01]\n",
      "   [ 1.06702547e+01 -6.70349121e-01 -3.17214584e+01]\n",
      "   [ 2.79111624e+00  5.33738995e+00 -3.69310226e+01]]\n",
      "\n",
      "  [[ 2.00303040e+01  2.69234581e+01 -1.02086926e+01]\n",
      "   [ 1.26265850e+01 -1.60635757e+00 -3.10819645e+01]\n",
      "   [ 1.16317005e+01 -1.52781487e+00 -3.01882172e+01]\n",
      "   ...\n",
      "   [ 1.38212585e+01 -3.52637291e+00 -2.95418053e+01]\n",
      "   [ 1.12836647e+01 -3.54824829e+00 -3.13552895e+01]\n",
      "   [ 2.99544239e+00  5.07718277e+00 -3.64287910e+01]]\n",
      "\n",
      "  [[ 4.90208244e+00  1.08829136e+01 -8.56527901e+00]\n",
      "   [ 5.05278587e-01 -7.75673485e+00 -2.37519302e+01]\n",
      "   [ 4.14847374e-01 -7.80641937e+00 -2.15634651e+01]\n",
      "   ...\n",
      "   [-4.81252670e-02 -9.44747543e+00 -2.12238312e+01]\n",
      "   [-2.02305937e+00 -9.28841400e+00 -2.22159443e+01]\n",
      "   [ 5.77032852e+00 -1.94152451e+00 -3.13930473e+01]]]\n",
      "\n",
      "\n",
      " [[[ 2.09226310e-01  7.91610479e-01 -3.57156754e-01]\n",
      "   [ 1.89043060e-01  7.79218376e-01 -4.92230594e-01]\n",
      "   [-1.66628942e-01  3.36148441e-01 -8.52626681e-01]\n",
      "   ...\n",
      "   [ 2.52627313e-01  1.73815697e-01  1.71198636e-01]\n",
      "   [-2.43440688e-01  3.04488361e-01 -2.77964652e-01]\n",
      "   [ 4.58607018e-01 -1.27406135e-01  1.12663671e-01]]\n",
      "\n",
      "  [[-3.77497673e-02  8.57317269e-01 -1.34959489e-01]\n",
      "   [ 2.21994519e-02  4.61212516e-01 -8.38746309e-01]\n",
      "   [-2.68830732e-02  9.33105946e-02 -2.40537211e-01]\n",
      "   ...\n",
      "   [-4.94765878e-01 -5.01978844e-02 -6.26653314e-01]\n",
      "   [-6.37081742e-01  1.34638518e-01 -9.55653191e-01]\n",
      "   [ 4.45894659e-01  8.97350073e-01 -1.18237114e+00]]\n",
      "\n",
      "  [[-1.38758302e-01  7.51755759e-02  4.68054146e-01]\n",
      "   [ 5.21802306e-01 -5.02339542e-01 -1.80563420e-01]\n",
      "   [-1.34942949e-01  1.09037191e-01 -2.42084458e-01]\n",
      "   ...\n",
      "   [-1.37464762e-01  6.69076264e-01 -5.42705536e-01]\n",
      "   [ 6.58580840e-01  8.36206913e-01 -4.72927094e-01]\n",
      "   [ 9.24557686e-01  7.39779830e-01 -1.15881443e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 3.78377587e-02  1.88418120e-01  8.01844820e-02]\n",
      "   [ 2.77086616e-01  4.09598559e-01  2.53382921e-01]\n",
      "   [ 9.31717157e-01 -2.78220177e-02  1.02756351e-01]\n",
      "   ...\n",
      "   [ 1.91969085e+00  8.82923841e-01 -6.81502104e-01]\n",
      "   [ 8.71108413e-01 -3.82157326e-01  1.29898399e-01]\n",
      "   [ 4.90443587e-01  5.22764921e-01 -6.04531825e-01]]\n",
      "\n",
      "  [[-1.92423120e-01  3.83113205e-01  2.20063359e-01]\n",
      "   [ 6.59253955e-01  6.46244526e-01 -3.37892324e-02]\n",
      "   [ 2.90816844e-01  5.36928475e-01 -7.05018997e-01]\n",
      "   ...\n",
      "   [ 7.14453876e-01  7.35210896e-01 -1.81767866e-01]\n",
      "   [ 3.87640297e-01  3.63264710e-01 -3.01454425e-01]\n",
      "   [ 2.55716830e-01  8.22421312e-01 -7.87858129e-01]]\n",
      "\n",
      "  [[-9.12209749e-02  2.43003994e-01  6.52724206e-02]\n",
      "   [-1.87620521e-01  2.61860043e-01 -2.40731463e-01]\n",
      "   [ 2.51702785e-01  1.34235352e-01 -4.90670681e-01]\n",
      "   ...\n",
      "   [ 2.71644950e-01 -3.32114160e-01  1.42263323e-01]\n",
      "   [-7.81013966e-02  2.20738947e-01  9.46419686e-02]\n",
      "   [ 1.93946421e-01 -3.85931283e-02 -5.69354117e-01]]]\n",
      "\n",
      "\n",
      " [[[ 3.44443550e+01  6.86726303e+01 -2.08745289e+01]\n",
      "   [ 6.02505112e+00  3.39041252e+01 -3.63906898e+01]\n",
      "   [ 6.67451477e+00  3.35314445e+01 -3.64360123e+01]\n",
      "   ...\n",
      "   [ 6.19903183e+00  3.23422699e+01 -3.53553429e+01]\n",
      "   [ 6.04497910e+00  3.31720505e+01 -3.78598137e+01]\n",
      "   [-1.94693661e+00  1.04231491e+01 -2.18407936e+01]]\n",
      "\n",
      "  [[ 4.04868011e+01  5.31960526e+01 -2.36197300e+01]\n",
      "   [ 2.13084679e+01 -5.36279678e+00 -6.10761909e+01]\n",
      "   [ 2.10322933e+01 -3.86911011e+00 -6.10284538e+01]\n",
      "   ...\n",
      "   [ 2.07464657e+01 -4.89583206e+00 -6.04252243e+01]\n",
      "   [ 1.91487694e+01 -4.33602524e+00 -6.29751282e+01]\n",
      "   [ 3.11850214e+00  7.89159775e+00 -7.24054260e+01]]\n",
      "\n",
      "  [[ 4.10334549e+01  5.38113403e+01 -2.41088371e+01]\n",
      "   [ 2.33544369e+01 -3.33250046e+00 -6.21592484e+01]\n",
      "   [ 2.30965538e+01 -2.68578720e+00 -6.24013443e+01]\n",
      "   ...\n",
      "   [ 2.30410614e+01 -4.65096664e+00 -6.06754379e+01]\n",
      "   [ 2.09256248e+01 -4.79318619e+00 -6.20576859e+01]\n",
      "   [ 3.89176083e+00  8.06150055e+00 -7.33080597e+01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 4.31212730e+01  5.53665466e+01 -2.42649593e+01]\n",
      "   [ 2.41405354e+01 -2.91997910e+00 -6.13850479e+01]\n",
      "   [ 2.38592110e+01 -1.49948120e+00 -6.02547112e+01]\n",
      "   ...\n",
      "   [ 2.42863941e+01 -3.28587723e+00 -5.89677849e+01]\n",
      "   [ 2.13085403e+01 -2.99480820e+00 -6.14631653e+01]\n",
      "   [ 4.23597145e+00  9.50564003e+00 -7.23913498e+01]]\n",
      "\n",
      "  [[ 4.01703110e+01  5.27617035e+01 -2.21212254e+01]\n",
      "   [ 2.31721001e+01 -4.00172043e+00 -6.08037224e+01]\n",
      "   [ 2.22458191e+01 -3.74693298e+00 -5.97900658e+01]\n",
      "   ...\n",
      "   [ 2.45041828e+01 -5.77214050e+00 -5.92724075e+01]\n",
      "   [ 2.20814095e+01 -5.88887024e+00 -6.08562851e+01]\n",
      "   [ 4.55206394e+00  9.36478043e+00 -7.21158676e+01]]\n",
      "\n",
      "  [[ 1.04357395e+01  1.96657333e+01 -1.81349525e+01]\n",
      "   [-8.39395523e-02 -1.66992874e+01 -4.55382156e+01]\n",
      "   [-1.46076202e-01 -1.68107567e+01 -4.33157463e+01]\n",
      "   ...\n",
      "   [-5.93687057e-01 -1.85370102e+01 -4.28578606e+01]\n",
      "   [-2.44159508e+00 -1.83775253e+01 -4.38664703e+01]\n",
      "   [ 1.12205429e+01 -3.91127586e+00 -6.13419456e+01]]]], shape=(32, 64, 64, 3), dtype=float32)\n",
      "Training step completed\n",
      "tf.Tensor(\n",
      "[[[[-1.42726088e+00  2.46556282e-01  6.81061089e-01]\n",
      "   [ 1.55550647e+00 -1.34985244e+00 -3.94481361e-01]\n",
      "   [ 2.65839577e-01 -9.09162700e-01  7.92370081e-01]\n",
      "   ...\n",
      "   [ 2.56481260e-01  2.14542603e+00 -6.23029649e-01]\n",
      "   [-6.40770435e-01 -1.13866889e+00  1.64799422e-01]\n",
      "   [ 7.05505610e-02 -8.61254632e-02 -2.03162819e-01]]\n",
      "\n",
      "  [[-3.67480308e-01  6.48705810e-02  4.09672052e-01]\n",
      "   [-1.46660697e+00 -5.43650687e-01 -2.01683015e-01]\n",
      "   [-1.51961720e+00  3.98405105e-01 -1.04808986e-01]\n",
      "   ...\n",
      "   [-5.65887809e-01 -1.36523813e-01 -5.56910098e-01]\n",
      "   [ 1.70183927e-01  1.13178122e+00  1.24299717e+00]\n",
      "   [ 6.05031431e-01 -5.02328992e-01 -2.58891201e+00]]\n",
      "\n",
      "  [[-1.51295781e+00  5.70715189e-01  7.41984129e-01]\n",
      "   [-6.09127760e-01 -9.97750878e-01  1.07029164e+00]\n",
      "   [ 8.85915399e-01 -1.80426466e+00 -6.67144835e-01]\n",
      "   ...\n",
      "   [-1.53105104e+00  4.41048235e-01 -8.22667718e-01]\n",
      "   [-5.75112581e-01 -2.15664792e+00  9.95296389e-02]\n",
      "   [-7.04535365e-01  3.37293267e-01  6.82060242e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 1.35529602e+00  1.41299295e+00 -3.83894801e-01]\n",
      "   [-3.04920733e-01 -2.20401812e+00 -1.31325603e+00]\n",
      "   [-1.91536561e-01  4.05701905e-01  6.99764714e-02]\n",
      "   ...\n",
      "   [ 7.02831507e-01 -6.88640535e-01 -5.71414471e-01]\n",
      "   [ 1.17667389e+00 -2.89104190e-02 -7.31159806e-01]\n",
      "   [ 2.29800522e-01 -2.53270340e+00  1.00378311e+00]]\n",
      "\n",
      "  [[-2.48448271e-03 -5.15861630e-01  3.51883709e-01]\n",
      "   [-1.15815592e+00  6.68637395e-01 -7.21694112e-01]\n",
      "   [ 9.45750713e-01  2.18012500e+00  5.09430707e-01]\n",
      "   ...\n",
      "   [-5.49156427e-01 -8.17745149e-01  4.18031007e-01]\n",
      "   [-1.65614879e+00  9.59253728e-01 -4.09017503e-01]\n",
      "   [-2.23630047e+00 -6.75009787e-01  1.38284171e+00]]\n",
      "\n",
      "  [[ 7.77544975e-02  1.70930877e-01  2.55857319e-01]\n",
      "   [ 3.08531821e-01 -6.72786117e-01 -7.30082631e-01]\n",
      "   [-8.40605438e-01 -3.91895184e-03 -3.22840184e-01]\n",
      "   ...\n",
      "   [ 3.75583887e-01 -7.78043568e-01  1.21475220e+00]\n",
      "   [-3.10575068e-01 -5.55566370e-01 -5.36805749e-01]\n",
      "   [ 3.94651771e-01  2.21633244e+00 -5.17048299e-01]]]], shape=(1, 64, 64, 3), dtype=float32)\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Exception encountered when calling layer 'ddpm_1' (type DDPM).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [999,64,64,64] vs. [998,1,1,64] [Op:AddV2] name: \n\nCall arguments received by layer 'ddpm_1' (type DDPM):\n   x=tf.Tensor(shape=(999, 64, 64, 3), dtype=float32)\n   t=tf.Tensor(shape=(1, 998), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining step completed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Generate a sample image\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m generated_image \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_images\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample image generated\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/src/models/ddpm.py:111\u001b[0m, in \u001b[0;36mgenerate_images\u001b[0;34m(self, num_images)\u001b[0m\n\u001b[1;32m    109\u001b[0m predicted_noise \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m(x, t)\n\u001b[1;32m    110\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas[i]\n\u001b[0;32m--> 111\u001b[0m alpha_cumprod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malphas_cumprod[i]\n\u001b[1;32m    112\u001b[0m beta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbetas[i]\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/tf_2_14/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Code/2023/face_generation/src/models/ddpm.py:61\u001b[0m, in \u001b[0;36mDDPM.call\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Down-sampling\u001b[39;00m\n\u001b[1;32m     60\u001b[0m x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown1(x)\n\u001b[0;32m---> 61\u001b[0m x1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb1(t)[:, tf\u001b[38;5;241m.\u001b[39mnewaxis, tf\u001b[38;5;241m.\u001b[39mnewaxis, :]\n\u001b[1;32m     62\u001b[0m x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdown2(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mMaxPooling2D()(x1))\n\u001b[1;32m     63\u001b[0m x2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime_emb2(t)[:, tf\u001b[38;5;241m.\u001b[39mnewaxis, tf\u001b[38;5;241m.\u001b[39mnewaxis, :]\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Exception encountered when calling layer 'ddpm_1' (type DDPM).\n\n{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:CPU:0}} Incompatible shapes: [999,64,64,64] vs. [998,1,1,64] [Op:AddV2] name: \n\nCall arguments received by layer 'ddpm_1' (type DDPM):\n   x=tf.Tensor(shape=(999, 64, 64, 3), dtype=float32)\n   t=tf.Tensor(shape=(1, 998), dtype=float32)"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "LATENT_DIM = 512\n",
    "STYLE_DIM = 512\n",
    "NUM_LAYERS = 8\n",
    "CHANNELS = [512, 256, 128, 64]\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "model = DDPM()\n",
    "model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=2e-4))\n",
    "\n",
    "# Generate dummy data for demonstration\n",
    "dummy_images = tf.random.normal([BATCH_SIZE, 64, 64, 3])\n",
    "\n",
    "# Train for one step (in practice, you would train for many steps)\n",
    "model.train_step(dummy_images)\n",
    "\n",
    "print(\"Training step completed\")\n",
    "\n",
    "# Generate a sample image\n",
    "generated_image = model.generate_images(num_images=1)\n",
    "print(\"Sample image generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> aa25840 (Laptop commit)
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
<<<<<<< HEAD
   "source": [
    "# Example usage\n",
    "latent_dim = 100\n",
    "generator = create_generator(latent_dim)\n",
    "discriminator = create_discriminator()\n",
    "\n",
    "wgan = WGAN_GP(generator, discriminator, latent_dim)\n",
    "\n",
    "# Define optimizers\n",
    "generator_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0, beta_2=0.9)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0, beta_2=0.9)\n",
    "\n",
    "# Define loss functions\n",
    "def discriminator_loss(real_logits, fake_logits):\n",
    "    return tf.reduce_mean(fake_logits) - tf.reduce_mean(real_logits)\n",
    "\n",
    "def generator_loss(fake_logits):\n",
    "    return -tf.reduce_mean(fake_logits)\n",
    "\n",
    "wgan.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    d_loss_fn=discriminator_loss,\n",
    "    g_loss_fn=generator_loss,\n",
    ")\n",
    "\n",
    "# Train the model (you'll need to prepare your dataset)\n",
    "# wgan.fit(dataset, epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
=======
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
>>>>>>> aa25840 (Laptop commit)
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
